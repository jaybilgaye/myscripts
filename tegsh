Here’s your full script with one new, self-contained block that activates only when you pass -del_month=YYYYMM. It deletes any item whose path contains a partition token like start_dt=YYYYMMDD or dt=YYYYMM, and whose first 6 digits equal the target month. The rest of the logic is unchanged.

#!/bin/bash

###### The purpose of the script is to delete older data from HDFS according to requirements.
###### The script uses a configuration file which contains comma (,) separated values of base directories and respective age.
###### The config file can be updated/modified however it is not encouraged to update the script.
###### Alarm event will be logged if a deletion fails.
###### Author: Vivian Li, Telstra
#MNPD: hdfs://asiago-hdp/RAW/MNPD/IOM/TRNAM/
#OMEGA: hdfs://rome-model/OMEGA/RAW/SAMISD/

CONFFILENAME=/opt/telstra/omega/omega-mgmt-current/hdfs-ageing/conf/hdfs-ageing.conf
LOGFILENAME=/var/log/omega/hdfs-ageing/hdfs_ageing.log

# LOGFILESIZE in bytes
LOGFILESIZE=10485760
# NUMLOGFILES log files to retain
NUMLOGFILES=5
VERSION=omega-mgmt-1.0.0
debug=1

# NEW: optional ad-hoc month purge argument, e.g. -del_month=202507
DEL_MONTH=""

# logJson Usage:
# logJson $logLevel $feedName $path $message
# Or:
# logJson $logLevel $message

logJson(){
    if ! [[ $1 == "DEBUG" && $debug == "0" ]]; then
        CURRTIME=`date '+%Y-%m-%d %H:%M:%S.%3N'`
        inputNum=$#

        # EOF must start from beginning of line
        if [[ $inputNum -gt 2 ]]; then
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "feedName":"$2", "path":"$3", "transactionType":"DeleteHDFSAgeingFile", "message":"$4"}
EOF
        else
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "transactionType":"DeleteHDFSAgeingFile", "message":"$2"}
EOF
        fi
    fi
}

# parameter: $feedName $fileName $message $alarmID
alarmJson(){
cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"ALARM", "alarmID":"$4", "feedName":"$1", "transactionType":"DeleteHDFSAgeingFile", "path":"$2", "message":"$3"}
EOF
}

logJson "INFO" "$0 started"

for var in "$@"
do
    var1=$(echo $var | cut -f1 -d=)
    var2=$(echo $var | cut -f2 -d=)
    if [[ $var1 == "-debug" ]]; then
        debug=1
    fi
    # NEW: parse -del_month=YYYYMM (6 digits)
    if [[ $var1 == "-del_month" ]]; then
        DEL_MONTH="$var2"
        if ! [[ "$DEL_MONTH" =~ ^[0-9]{6}$ ]]; then
            logJson "ALARM" "Invalid -del_month value \"$DEL_MONTH\". Expected YYYYMM."
            echo "ERROR: Invalid -del_month value \"$DEL_MONTH\". Expected YYYYMM." >&2
            exit 2
        fi
        logJson "INFO" "Ad-hoc month purge requested for $DEL_MONTH"
    fi
done

today=`date +'%s'`

###### Checking whether the config file exists.
if [ ! -f $CONFFILENAME ]; then
    logJson "INFO" "Configuration file \"$CONFFILENAME\" not present; exiting the script......."
    exit 1
fi

for entry in `cat ${CONFFILENAME} | grep -v ^#`
do
    feedName=`echo $entry | awk -F"," '{print $1}'`
    dir=`echo $entry | awk -F"," '{print $2}'`
    age=`echo $entry | awk -F"," '{print $3}'`
    alarmID=`echo $entry | awk -F"," '{print $4}'`

    logJson "DEBUG" "$feedName" "$dir" "age threshold is $age"

    result=`/usr/bin/hdfs dfs -ls "${dir}" 2>&1`
    rtn=$?
    if [[ $rtn -ne 0 ]]; then
        #feedName fileName message alarmID
        alarmJson "$feedName" "$dir" "Fail to read HDFS folder" "$alarmID"
    else
        /usr/bin/hdfs dfs -ls "${dir}" | while read line; do

            # ==== NEW BLOCK: ad-hoc month purge when -del_month=YYYYMM is provided ====
            if [[ -n "$DEL_MONTH" ]]; then
                filePath_month=$(echo ${line} | awk '{print $8}')
                if [[ -n "$filePath_month" ]]; then
                    # Try start_dt= first, then dt=
                    part_token=$(echo "$filePath_month" | sed -n 's/.*start_dt=\([0-9]\{6,10\}\).*/\1/p')
                    if [[ -z "$part_token" ]]; then
                        part_token=$(echo "$filePath_month" | sed -n 's/.*dt=\([0-9]\{6,10\}\).*/\1/p')
                    fi

                    if [[ -n "$part_token" ]]; then
                        part_yyyymm=${part_token:0:6}
                        if [[ "$part_yyyymm" == "$DEL_MONTH" ]]; then
                            logJson "INFO" "$feedName" "$filePath_month" "Matched month $DEL_MONTH by partition token, deleting"
                            result=`/usr/bin/hdfs dfs -rm -r -skipTrash "$filePath_month" 2>&1`
                            rtn=$?
                            if [[ $rtn -ne 0 ]]; then
                                alarmJson "$feedName" "$filePath_month" "Failed to delete in month purge $DEL_MONTH" "$alarmID"
                            else
                                logJson "INFO" "$feedName" "$filePath_month" "Deleted via month purge $DEL_MONTH"
                            fi
                            continue
                        else
                            logJson "DEBUG" "$feedName" "$filePath_month" "Partition month $part_yyyymm != target $DEL_MONTH"
                        fi
                    else
                        logJson "DEBUG" "$feedName" "$filePath_month" "No start_dt= or dt= token found, skipping month check"
                    fi
                fi
                # If no match, fall through to original mtime logic below
            fi
            # ==== END NEW BLOCK =======================================================

            dir_date=$(echo ${line} | awk '{print $6}')
            if [[ ! -z "$dir_date" ]]
            then
                difference=$(( ( $today - $(date -d ${dir_date} +%s) ) / (24*60*60) ))
                filePath=$(echo ${line} | awk '{print $8}')

                logJson "DEBUG" "$feedName" "$filePath" "dir_date is $dir_date, age is $difference"

                if [[ ${difference} -gt ${age} ]]; then
                    result=`/usr/bin/hdfs dfs -rm -r -skipTrash $filePath 2>&1`
                    rtn=$?
                    if [[ $rtn -ne 0 ]]; then
                        alarmJson "$feedName" "$filePath" "Fail to delete aged HDFS file" "$alarmID"
                    else
                        logJson "INFO" "$feedName" "$filePath" "Successfully deleted aged HDFS file"
                    fi
                fi
            fi
        done
    fi
done

logJson "INFO" "$0 finished"

CURRSIZE=`ls -altr $LOGFILENAME | cut -f5 -d' '`
if (( CURRSIZE > LOGFILESIZE ))
then
    CURRDATEANDTIME=`date +%Y_%m_%d_%H_%M`
    NEWLOGFILENAME=$LOGFILENAME.$CURRDATEANDTIME
    mv $LOGFILENAME $NEWLOGFILENAME
    touch $LOGFILENAME
    BACKUPFILESLIST=(`ls -alt $LOGFILENAME* | awk '$1=$1' | cut -f9 -d' '`)
    BACKUPFILESLISTLENGTH=${#BACKUPFILESLIST[@]}
    logJson "DEBUG" "Rotate log file"
    for (( i=$NUMLOGFILES+1; i<$BACKUPFILESLISTLENGTH; i++ ))
    do
        # Before deleting, double check to make sure that
        # it is the log file that we are deleting
        if [[ ${BACKUPFILESLIST[$i]} = *$LOGFILENAME* ]]
        then
            logJson "DEBUG" "remove old log ${BACKUPFILESLIST[$i]}"
            rm ${BACKUPFILESLIST[$i]}
        fi
    done
fi

exit 0

How it works

1. Pass -del_month=YYYYMM only when you want an ad-hoc targeted purge for that month.


2. The new block looks for either start_dt= or dt= in each item path. It reads 6 to 10 digits after the token, then compares the first 6 digits to YYYYMM.


3. If they match, it deletes that path immediately and moves to the next item. If they do not match or the token is absent, the original mtime based logic runs as before.



Examples to run Delete all partitions for July 2025 in one ad-hoc run

./hdfs_ageing.sh -del_month=202507

Keep original behavior, no ad-hoc purge

./hdfs_ageing.sh

Notes Paths like these will be matched /Tatra/raw/truecall/start_dt=20270805 /data/curated/dt=202507

Use a quick dry test on a non-critical directory if you want to validate the matching first.



=====



Got it 👍 — you want a clean version that uses only the partition date (start_dt=YYYYMMDD) for the retention check, and completely drop the old mtime branch.

Here’s the updated script (full) with mtime logic removed and replaced with partition date logic only:

#!/bin/bash

###### The purpose of the script is to delete older data from HDFS according to requirements.
###### The script uses a configuration file which contains comma (,) separated values of base directories and respective age.
###### The config file can be updated/modified however it is not encouraged to update the script.
###### Alarm event will be logged if a deletion fails.
###### Author: Vivian Li, Telstra
#MNPD: hdfs://asiago-hdp/RAW/MNPD/IOM/TRNAM/
#OMEGA: hdfs://rome-model/OMEGA/RAW/SAMISD/

CONFFILENAME=/opt/telstra/omega/omega-mgmt-current/hdfs-ageing/conf/hdfs-ageing.conf
LOGFILENAME=/var/log/omega/hdfs-ageing/hdfs_ageing.log

# LOGFILESIZE in bytes
LOGFILESIZE=10485760
# NUMLOGFILES log files to retain
NUMLOGFILES=5
VERSION=omega-mgmt-1.0.0
debug=1

# logJson Usage:
# logJson $logLevel $feedName $path $message
# Or:
# logJson $logLevel $message

logJson(){
    if ! [[ $1 == "DEBUG" && $debug == "0" ]]; then
        CURRTIME=`date '+%Y-%m-%d %H:%M:%S.%3N'`
        inputNum=$#

        # EOF must start from beginning of line
        if [[ $inputNum -gt 2 ]]; then
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "feedName":"$2", "path":"$3", "transactionType":"DeleteHDFSAgeingFile", "message":"$4"}
EOF
        else
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "transactionType":"DeleteHDFSAgeingFile", "message":"$2"}
EOF
        fi
    fi
}

# parameter: $feedName $fileName $message $alarmID
alarmJson(){
cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"ALARM", "alarmID":"$4", "feedName":"$1", "transactionType":"DeleteHDFSAgeingFile", "path":"$2", "message":"$3"}
EOF
}

logJson "INFO" "$0 started"

for var in "$@"
do
    var1=$(echo $var | cut -f1 -d=)
    var2=$(echo $var | cut -f2 -d=)
    if [[ $var1 == "-debug" ]]; then
        debug=1
    fi
done

today=`date +'%s'`

###### Checking whether the config file exists.
if [ ! -f $CONFFILENAME ]; then
    logJson "INFO" "Configuration file \"$CONFFILENAME\" not present; exiting the script......."
    exit 1
fi

for entry in `cat ${CONFFILENAME} | grep -v ^#`
do
    feedName=`echo $entry | awk -F"," '{print $1}'`
    dir=`echo $entry | awk -F"," '{print $2}'`
    age=`echo $entry | awk -F"," '{print $3}'`
    alarmID=`echo $entry | awk -F"," '{print $4}'`

    logJson "DEBUG" "$feedName" "$dir" "age threshold is $age"

    # cutoff_ymd = today - age days, formatted as YYYYMMDD
    cutoff_ymd=`date -d "$age days ago" +%Y%m%d`

    result=`/usr/bin/hdfs dfs -ls "${dir}" 2>&1`
    rtn=$?
    if [[ $rtn -ne 0 ]]; then
        #feedName fileName message alarmID
        alarmJson "$feedName" "$dir" "Fail to read HDFS folder" "$alarmID"
    else
        /usr/bin/hdfs dfs -ls "${dir}" | while read line; do
            filePath=$(echo ${line} | awk '{print $8}')
            if [[ -z "$filePath" ]]; then
                continue
            fi

            # Extract start_dt=YYYYMMDD from path
            part_token=$(echo "$filePath" | sed -n 's/.*start_dt=\([0-9]\{8\}\).*/\1/p')

            if [[ -z "$part_token" ]]; then
                logJson "DEBUG" "$feedName" "$filePath" "No start_dt=YYYYMMDD token found → skip"
                continue
            fi

            # Compare partition date (YYYYMMDD) with cutoff
            if [[ "$part_token" < "$cutoff_ymd" ]]; then
                logJson "DEBUG" "$feedName" "$filePath" "partition start_dt=$part_token < cutoff $cutoff_ymd (age=$age d) → delete"
                result=`/usr/bin/hdfs dfs -rm -r -skipTrash "$filePath" 2>&1`
                rtn=$?
                if [[ $rtn -ne 0 ]]; then
                    alarmJson "$feedName" "$filePath" "Fail to delete HDFS path by partition date" "$alarmID"
                else
                    logJson "INFO" "$feedName" "$filePath" "Deleted by partition date (start_dt)"
                fi
            else
                logJson "DEBUG" "$feedName" "$filePath" "partition start_dt=$part_token >= cutoff $cutoff_ymd → keep"
            fi
        done
    fi
done

logJson "INFO" "$0 finished"

CURRSIZE=`ls -altr $LOGFILENAME | cut -f5 -d' '`
if (( CURRSIZE > LOGFILESIZE ))
then
    CURRDATEANDTIME=`date +%Y_%m_%d_%H_%M`
    NEWLOGFILENAME=$LOGFILENAME.$CURRDATEANDTIME
    mv $LOGFILENAME $NEWLOGFILENAME
    touch $LOGFILENAME
    BACKUPFILESLIST=(`ls -alt $LOGFILENAME* | awk '$1=$1' | cut -f9 -d' '`)
    BACKUPFILESLISTLENGTH=${#BACKUPFILESLIST[@]}
    logJson "DEBUG" "Rotate log file"
    for (( i=$NUMLOGFILES+1 ; i<$BACKUPFILESLISTLENGTH ; i++ ))
    do
        if [[ ${BACKUPFILESLIST[$i]} = *$LOGFILENAME* ]]
        then
            logJson "DEBUG" "remove old log ${BACKUPFILESLIST[$i]}"
            rm ${BACKUPFILESLIST[$i]}
        fi
    done
fi

exit 0


⸻

Key changes
	1.	Removed mtime checks (dir_date, $6 column, difference calculation).
	2.	Added logic to:
	•	Precompute cutoff_ymd = today - age days.
	•	Extract start_dt=YYYYMMDD from the path.
	•	Compare part_token (YYYYMMDD) with cutoff_ymd.
	•	Delete if older, log if not.

⸻

✅ Now the script interprets age exclusively against the partition date (start_dt) rather than file modification time.

Do you want me to also add a fallback to mtime in case a path doesn’t have start_dt=…, or should it strictly ignore/delete only based on partition date?



==================





