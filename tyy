Here is the complete script with the original logic kept intact. I added a single new block that activates only when you pass -del_month=YYYYMM. This block matches paths that contain start_dt=YYYYMMDD, compares the first 6 digits (YYYYMM) to your target month, and deletes on match. The rest of the script runs exactly as before.

#!/bin/bash

###### The purpose of the script is to delete older data from HDFS according to requirements.
###### The script uses a configuration file which contains comma (,) separated values of base directories and respective age.
###### The config file can be updated/modified however it is not encouraged to update the script.
###### Alarm event will be logged if a deletion fails.
###### Author: Vivian Li, Telstra
#MNPD: hdfs://asiago-hdp/RAW/MNPD/IOM/TRNAM/
#OMEGA: hdfs://rome-model/OMEGA/RAW/SAMISD/

CONFFILENAME=/opt/telstra/omega/omega-mgmt-current/hdfs-ageing/conf/hdfs-ageing.conf
LOGFILENAME=/var/log/omega/hdfs-ageing/hdfs_ageing.log

# LOGFILESIZE in bytes
LOGFILESIZE=10485760
# NUMLOGFILES log files to retain
NUMLOGFILES=5
VERSION=omega-mgmt-1.0.0
debug=1

# NEW: optional ad-hoc month purge argument, e.g. -del_month=202507
# This only looks for start_dt=YYYYMMDD in the path and matches by YYYYMM
DEL_MONTH=""

# logJson Usage:
# logJson $logLevel $feedName $path $message
# Or:
# logJson $logLevel $message

logJson(){
    if ! [[ $1 == "DEBUG" && $debug == "0" ]]; then
        CURRTIME=`date '+%Y-%m-%d %H:%M:%S.%3N'`
        inputNum=$#

        # EOF must start from beginning of line
        if [[ $inputNum -gt 2 ]]; then
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "feedName":"$2", "path":"$3", "transactionType":"DeleteHDFSAgeingFile", "message":"$4"}
EOF
        else
            cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"$1", "transactionType":"DeleteHDFSAgeingFile", "message":"$2"}
EOF
        fi
    fi
}

# parameter: $feedName $fileName $message $alarmID
alarmJson(){
cat << EOF >> $LOGFILENAME
{"version":"$VERSION", "timestamp":"$CURRTIME", "logLevel":"ALARM", "alarmID":"$4", "feedName":"$1", "transactionType":"DeleteHDFSAgeingFile", "path":"$2", "message":"$3"}
EOF
}

logJson "INFO" "$0 started"

for var in "$@"
do
    var1=$(echo $var | cut -f1 -d=)
    var2=$(echo $var | cut -f2 -d=)
    if [[ $var1 == "-debug" ]]; then
        debug=1
    fi
    # NEW: parse -del_month=YYYYMM for ad-hoc month purge by start_dt=YYYYMMDD
    if [[ $var1 == "-del_month" ]]; then
        DEL_MONTH="$var2"
        if ! [[ "$DEL_MONTH" =~ ^[0-9]{6}$ ]]; then
            logJson "ALARM" "Invalid -del_month value \"$DEL_MONTH\". Expected YYYYMM."
            echo "ERROR: Invalid -del_month value \"$DEL_MONTH\". Expected YYYYMM." >&2
            exit 2
        fi
        logJson "INFO" "Ad-hoc month purge requested for $DEL_MONTH"
    fi
done

today=`date +'%s'`

###### Checking whether the config file exists.
if [ ! -f $CONFFILENAME ]; then
    logJson "INFO" "Configuration file \"$CONFFILENAME\" not present; exiting the script......."
    exit 1
fi

for entry in `cat ${CONFFILENAME} | grep -v ^#`
do
    feedName=`echo $entry | awk -F"," '{print $1}'`
    dir=`echo $entry | awk -F"," '{print $2}'`
    age=`echo $entry | awk -F"," '{print $3}'`
    alarmID=`echo $entry | awk -F"," '{print $4}'`

    logJson "DEBUG" "$feedName" "$dir" "age threshold is $age"

    result=`/usr/bin/hdfs dfs -ls "${dir}" 2>&1`
    rtn=$?
    if [[ $rtn -ne 0 ]]; then
        #feedName fileName message alarmID
        alarmJson "$feedName" "$dir" "Fail to read HDFS folder" "$alarmID"
    else
        /usr/bin/hdfs dfs -ls "${dir}" | while read line; do

            #######################################################################
            # NEW BLOCK: ad-hoc month purge driven by -del_month=YYYYMM
            # Matches only partitions of the form start_dt=YYYYMMDD in the path.
            # If the first 6 digits (YYYYMM) equal DEL_MONTH, delete immediately.
            # If there is no match or DEL_MONTH is not set, fall through to original logic.
            #######################################################################
            if [[ -n "$DEL_MONTH" ]]; then
                filePath_month=$(echo ${line} | awk '{print $8}')
                if [[ -n "$filePath_month" ]]; then
                    # Extract 8 digits after start_dt= (strictly start_dt=YYYYMMDD)
                    part_token=$(echo "$filePath_month" | sed -n 's/.*start_dt=\([0-9]\{8\}\).*/\1/p')
                    if [[ -n "$part_token" ]]; then
                        part_yyyymm=${part_token:0:6}
                        if [[ "$part_yyyymm" == "$DEL_MONTH" ]]; then
                            logJson "INFO" "$feedName" "$filePath_month" "Matched start_dt month $DEL_MONTH, deleting"
                            result=`/usr/bin/hdfs dfs -rm -r -skipTrash "$filePath_month" 2>&1`
                            rtn=$?
                            if [[ $rtn -ne 0 ]]; then
                                alarmJson "$feedName" "$filePath_month" "Failed to delete in month purge $DEL_MONTH" "$alarmID"
                            else
                                logJson "INFO" "$feedName" "$filePath_month" "Deleted via month purge $DEL_MONTH"
                            fi
                            continue
                        else
                            logJson "DEBUG" "$feedName" "$filePath_month" "start_dt month $part_yyyymm != target $DEL_MONTH"
                        fi
                    else
                        logJson "DEBUG" "$feedName" "$filePath_month" "No start_dt=YYYYMMDD token found in path"
                    fi
                fi
                # If did not match or no token, proceed to the original mtime logic below
            fi
            #######################################################################
            # END NEW BLOCK
            #######################################################################

            dir_date=$(echo ${line} | awk '{print $6}')
            if [[ ! -z "$dir_date" ]]
            then
                difference=$(( ( $today - $(date -d ${dir_date} +%s) ) / (24*60*60) ))
                filePath=$(echo ${line} | awk '{print $8}')

                logJson "DEBUG" "$feedName" "$filePath" "dir_date is $dir_date, age is $difference"

                if [[ ${difference} -gt ${age} ]]; then
                    result=`/usr/bin/hdfs dfs -rm -r -skipTrash $filePath 2>&1`
                    rtn=$?
                    if [[ $rtn -ne 0 ]]; then
                        alarmJson "$feedName" "$filePath" "Fail to delete aged HDFS file" "$alarmID"
                    else
                        logJson "INFO" "$feedName" "$filePath" "Successfully deleted aged HDFS file"
                    fi
                fi
            fi
        done
    fi
done

logJson "INFO" "$0 finished"

CURRSIZE=`ls -altr $LOGFILENAME | cut -f5 -d' '`
if (( CURRSIZE > LOGFILESIZE ))
then
    CURRDATEANDTIME=`date +%Y_%m_%d_%H_%M`
    NEWLOGFILENAME=$LOGFILENAME.$CURRDATEANDTIME
    mv $LOGFILENAME $NEWLOGFILENAME
    touch $LOGFILENAME
    BACKUPFILESLIST=(`ls -alt $LOGFILENAME* | awk '$1=$1' | cut -f9 -d' '`)
    BACKUPFILESLISTLENGTH=${#BACKUPFILESLIST[@]}
    logJson "DEBUG" "Rotate log file"
    for (( i=$NUMLOGFILES+1; i<$BACKUPFILESLISTLENGTH; i++ ))
    do
        # Before deleting, double check to make sure that
        # it is the log file that we are deleting
        if [[ ${BACKUPFILESLIST[$i]} = *$LOGFILENAME* ]]
        then
            logJson "DEBUG" "remove old log ${BACKUPFILESLIST[$i]}"
            rm ${BACKUPFILESLIST[$i]}
        fi
    done
fi

exit 0

How to run

Delete all partitions for July 2025 that contain start_dt=YYYYMMDD in the path

./hdfs_ageing.sh -del_month=202507

Keep original behavior with mtime and retention

./hdfs_ageing.sh

This matches paths like

/Tatra/raw/truecall/start_dt=20270805
/data/curated/start_dt=20250715

