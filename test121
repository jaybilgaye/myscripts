
‚úÖ Goal

From the edge node, you will:
	1.	Run one script ‚Üí
	2.	Every Hadoop node runs its own backup (config only)
	3.	Edge node collects all tar.gz files into

~/hadoop-config-backups/<date>/


	4.	(Optional) Commit into Git for diffing.

No manual work on any node.

‚∏ª

‚úÖ STEP 1 ‚Äî Create a clean node list

On your edge node, create:

hadoop_hosts.txt

nn1
nn2
dn1
dn2
dn3
dn4
dn5
dn6
dn7
dn8
dn9
dn10
dn11
dn12
dn13
dn14
dn15
dn16

Use actual hostnames/IPs that are reachable by SSH.

‚∏ª

‚úÖ STEP 2 ‚Äî Create backup script ON EVERY NODE (via remote SSH)

Since you have SSH to all nodes, push the backup script to each node:

Backup script (store on each node)

Save this as /usr/local/bin/backup-hadoop.sh:

#!/bin/bash

DATE=$(date +%F)
BACKUP_DIR="/var/backups/hadoop-configs"
HADOOP_CONF="/etc/hadoop/hadoop-3.4.1/etc/hadoop"

sudo mkdir -p $BACKUP_DIR

sudo tar czf $BACKUP_DIR/hadoop-config-$(hostname)-$DATE.tar.gz \
    $HADOOP_CONF \
    /etc/hosts \
    /etc/security/limits.conf \
    /etc/sysctl.conf \
    2>/dev/null

echo "Backup created: $BACKUP_DIR/hadoop-config-$(hostname)-$DATE.tar.gz"

Make it executable:

sudo chmod +x /usr/local/bin/backup-hadoop.sh

If you want, I can give you an automatic script that pushes this file to all nodes in one shot.

‚∏ª

‚úÖ STEP 3 ‚Äî One-shot master script on the EDGE NODE

This script:
	1.	SSH into each node
	2.	Runs backup script on that node
	3.	SCPs the tar file back to the edge node
	4.	Stores everything in a date folder

‚∏ª

collect-hadoop-configs.sh (run from EDGE NODE)

#!/bin/bash

DATE=$(date +%F)
OUT_DIR="$HOME/hadoop-config-backups/$DATE"
mkdir -p "$OUT_DIR"

while read host; do
    echo "========== $host =========="
    
    # Run backup on the remote node
    ssh -o StrictHostKeyChecking=no $host "sudo /usr/local/bin/backup-hadoop.sh"
    
    # Copy file to edge node
    scp -o StrictHostKeyChecking=no \
        $host:/var/backups/hadoop-configs/hadoop-config-$host-$DATE.tar.gz \
        "$OUT_DIR/"
done < hadoop_hosts.txt

echo "===================================="
echo "All backups stored at: $OUT_DIR"
echo "===================================="

Run:

chmod +x collect-hadoop-configs.sh
./collect-hadoop-configs.sh


‚∏ª

üì¶ Final output will look like:

~/hadoop-config-backups/2025-11-25/
    hadoop-config-nn1-2025-11-25.tar.gz
    hadoop-config-nn2-2025-11-25.tar.gz
    hadoop-config-dn1-2025-11-25.tar.gz
    ...
    hadoop-config-dn16-2025-11-25.tar.gz


‚∏ª

‚öôÔ∏è STEP 4 ‚Äî Optional (Highly Recommended): Commit to Git

On the edge node:

cd ~/hadoop-config-backups
mkdir config-history
cd config-history
tar xzf ../2025-11-25/hadoop-config-nn1-2025-11-25.tar.gz

git init
git add .
git commit -m "Initial Hadoop config snapshot"

Each time you run new backups:

tar xzf ../<new date>/hadoop-config-nn1-<date>.tar.gz
git add .
git diff
git commit -m "Updated config"

This gives you versioned, diff-able Hadoop configs.




Nice, we‚Äôll fold systemd service units into the same backup flow so you‚Äôve got everything needed to rebuild a node from scratch.

I‚Äôll give you ready-to-use scripts, updated to include:

1. Hadoop core configs


2. NameNode metadata


3. JournalNode shared edits


4. ZooKeeper data dir


5. OS-level configs


6. Systemd service units for Hadoop



You can paste these as-is and just tweak the NN/JN paths to match your cluster.


---

1Ô∏è‚É£ Per-node backup script (includes systemd units)

Create this file on every NN/DN/JN/ZK node:

/usr/local/bin/hadoop-full-backup.sh

#!/bin/bash

DATE=$(date +%F)
HOST=$(hostname)
BACKUP_DIR="/var/backups/hadoop-full"
HADOOP_CONF="/etc/hadoop/hadoop-3.4.1/etc/hadoop"

# ================================
# UPDATE THESE PATHS FOR YOUR CLUSTER
# ================================
# NameNode metadata dirs (from dfs.namenode.name.dir)
# Example: file:///data/nn1,file:///data/nn2  -> /data/nn1/current /data/nn2/current
NN_DIRS="/data/nn1/current /data/nn2/current"

# JournalNode shared edits dir (from dfs.namenode.shared.edits.dir)
# If you don't use QJM, leave as empty string ""
JN_DIR="/data/journal"

# ZooKeeper data directory (if this node is a ZK server)
ZK_DIR="/var/lib/zookeeper"

# Hadoop-related systemd unit files
SYSTEMD_UNITS="/etc/systemd/system/hadoop*.service \
/etc/systemd/system/hdfs*.service \
/etc/systemd/system/yarn*.service \
/etc/systemd/system/mapred*.service"

sudo mkdir -p "$BACKUP_DIR"

sudo tar czf "$BACKUP_DIR/hadoop-full-$HOST-$DATE.tar.gz" \
    "$HADOOP_CONF" \
    $NN_DIRS \
    $JN_DIR \
    $ZK_DIR \
    $SYSTEMD_UNITS \
    /etc/hosts \
    /etc/security/limits.conf \
    /etc/sysctl.conf \
    /etc/krb5.conf \
    2>/dev/null

echo "Backup created: $BACKUP_DIR/hadoop-full-$HOST-$DATE.tar.gz"

Make it executable:

sudo chmod +x /usr/local/bin/hadoop-full-backup.sh

> üîé Notes

On DNs that don‚Äôt have NN/JN/ZK dirs or systemd units matching the glob, tar will just skip them (we‚Äôre silencing errors with 2>/dev/null).

Just make sure NN_DIRS, JN_DIR, ZK_DIR are correct on the nodes where they do exist (NNs / JournalNodes / ZK nodes).




If needed, you can keep one version per role, but this single script works cluster-wide with harmless no-op paths.


---

2Ô∏è‚É£ Edge-node collector script (unchanged logic, new tar names)

On your edge node, create:

hadoop_hosts.txt (one host per line):

nn1
nn2
dn1
dn2
...
dn16

Then create:

collect-hadoop-full-backups.sh

#!/bin/bash

DATE=$(date +%F)
OUT_DIR="$HOME/hadoop-full-backups/$DATE"
mkdir -p "$OUT_DIR"

while read host; do
    [ -z "$host" ] && continue

    echo "========== $host =========="
    
    # Run full backup on the remote node
    ssh -o StrictHostKeyChecking=no "$host" \
        "sudo /usr/local/bin/hadoop-full-backup.sh"
    
    # Copy backup tarball back to edge node
    scp -o StrictHostKeyChecking=no \
        "$host:/var/backups/hadoop-full/hadoop-full-$host-$DATE.tar.gz" \
        "$OUT_DIR/" 2>/dev/null || echo "WARNING: Could not fetch backup from $host"
done < hadoop_hosts.txt

echo
echo "All backups stored at: $OUT_DIR"

Make executable and run:

chmod +x collect-hadoop-full-backups.sh
./collect-hadoop-full-backups.sh


---

3Ô∏è‚É£ (Optional) Cron job on edge node

To run this daily at 2:15 AM from your user on the edge node:

crontab -e

Add:

15 2 * * * /path/to/collect-hadoop-full-backups.sh >> $HOME/hadoop-full-backups/backup.log 2>&1


---

4Ô∏è‚É£ Quick recap of what you‚Äôre backing up now

Per node, each tarball includes:

Hadoop configs: /etc/hadoop/hadoop-3.4.1/etc/hadoop

NameNode metadata dirs: $NN_DIRS (fsimage + edits)

JournalNode shared edits dir: $JN_DIR

ZooKeeper data: $ZK_DIR

Systemd units:

/etc/systemd/system/hadoop*.service

/etc/systemd/system/hdfs*.service

/etc/systemd/system/yarn*.service

/etc/systemd/system/mapred*.service


OS-level configs:

/etc/hosts

/etc/security/limits.conf

/etc/sysctl.conf

/etc/krb5.conf



That‚Äôs enough to:

Rebuild nodes

Restore NN metadata

Keep HA and ZK state

Restore service definitions and OS tuning



---

If you want, next step I can give you a restore playbook:
‚ÄúGiven one of these tar.gz files, here‚Äôs exactly how to rebuild a dead DataNode / NameNode with minimal downtime.‚Äù

