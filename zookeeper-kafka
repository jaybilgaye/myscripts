

To verify that your Apache ZooKeeper installation is functioning correctly, you can perform the following tests:

1. Check ZooKeeper Server Status

Use the zkServer.sh script to determine the status of your ZooKeeper server: ï¿¼

sudo /usr/share/zookeeper/bin/zkServer.sh status

This command will output the mode of the server, such as leader, follower, or standalone, indicating its current role in the ensemble.  ï¿¼

2. Connect Using the ZooKeeper Command-Line Interface (CLI)

The zkCli.sh script allows you to interact with your ZooKeeper server: ï¿¼

sudo /usr/share/zookeeper/bin/zkCli.sh -server localhost:2181

This command connects you to the ZooKeeper server running on localhost at port 2181. Once connected, you can execute various commands to interact with the ZooKeeper service.

3. Create and Manage znodes

Within the ZooKeeper CLI, you can create, retrieve, and manage znodes (ZooKeeper data nodes): ï¿¼
	â€¢	Create a znode:

create /my_node "Hello, ZooKeeper!"

This command creates a new znode at path /my_node with the data "Hello, ZooKeeper!".  ï¿¼

	â€¢	Retrieve data from a znode:

get /my_node

This retrieves and displays the data stored in /my_node.

	â€¢	Set data for a znode:

set /my_node "Updated data"

This updates the data of /my_node to "Updated data".

	â€¢	List children of a znode:

ls /

This lists the children znodes of the root path /. ï¿¼

	â€¢	Delete a znode:

delete /my_node

This deletes the znode at /my_node. ï¿¼

4. Check ZooKeeper Server Mode Using Four-Letter Commands

ZooKeeper provides a set of four-letter commands to query the status of the server: ï¿¼
	â€¢	Determine the serverâ€™s mode:

echo srvr | nc localhost 2181

This command returns information about the server, including whether itâ€™s operating as a leader or follower.  ï¿¼

	â€¢	Check if the server is running:

echo ruok | nc localhost 2181

A healthy server responds with imok.  ï¿¼

By performing these tests, you can confirm that your ZooKeeper installation is operational and capable of handling client requests.




==
To ensure that ZooKeeper logs are directed to /var/log/zookeeper, youâ€™ll need to configure the logging settings appropriately. Hereâ€™s how you can achieve this:

â¸»

ğŸ› ï¸ Steps to Configure ZooKeeper Logging Directory
	1.	Locate the log4j.properties File:
	â€¢	This file is typically found in the conf directory of your ZooKeeper installation. ï¿¼
	â€¢	For example: /etc/zookeeper/conf/log4j.properties
	2.	Edit the log4j.properties File:
	â€¢	Open the file with your preferred text editor:

sudo vi /etc/zookeeper/conf/log4j.properties


	â€¢	Modify or add the following properties to set the log directory:

zookeeper.log.dir=/var/log/zookeeper
zookeeper.log.file=zookeeper.log


	â€¢	Ensure the appender is configured to use these properties: ï¿¼

log4j.appender.ROLLINGFILE.File=${zookeeper.log.dir}/${zookeeper.log.file}


	3.	Create the Log Directory (If It Doesnâ€™t Exist):
	â€¢	If /var/log/zookeeper doesnâ€™t already exist, create it and set appropriate permissions:

sudo mkdir -p /var/log/zookeeper
sudo chown zookeeper:zookeeper /var/log/zookeeper


	4.	Restart the ZooKeeper Service:
	â€¢	After making these changes, restart ZooKeeper to apply the new logging configuration: ï¿¼

sudo systemctl restart zookeeper



â¸»

ğŸ“Œ Additional Notes
	â€¢	Environment Variable Override:
	â€¢	You can also set the ZOO_LOG_DIR environment variable to specify the log directory: ï¿¼

export ZOO_LOG_DIR=/var/log/zookeeper


	â€¢	This can be added to the ZooKeeper startup script or systemd service file to ensure itâ€™s set on startup.

	â€¢	Logging Framework:
	â€¢	ZooKeeper uses Log4j for logging. Ensure that the Log4j configuration aligns with your desired logging behavior.

â¸»

By following these steps, ZooKeeper will write its logs to /var/log/zookeeper, helping you maintain organized and centralized log management.



Below is an example of a log4j.properties file configured for Apache ZooKeeper to store logs in /var/log/zookeeper:

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Set the root logger level and attach appenders to it
log4j.rootLogger=INFO, ROLLINGFILE, CONSOLE

# Configure the rolling file appender to write logs to /var/log/zookeeper
log4j.appender.ROLLINGFILE=org.apache.log4j.RollingFileAppender
log4j.appender.ROLLINGFILE.File=${zookeeper.log.dir}/${zookeeper.log.file}
log4j.appender.ROLLINGFILE.MaxFileSize=10MB
log4j.appender.ROLLINGFILE.MaxBackupIndex=10
log4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayout
log4j.appender.ROLLINGFILE.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} (%F:%L) - %m%n

# Configure the console appender for debugging purpose
log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender
log4j.appender.CONSOLE.Target=System.out
log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout
log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} (%F:%L) - %m%n

# Define log directory and file name
zookeeper.log.dir=/var/log/zookeeper
zookeeper.log.file=zookeeper.log

# Set logger levels for ZooKeeper internals
log4j.logger.org.apache.zookeeper=INFO
log4j.logger.org.apache.zookeeper.server=INFO



â¸»

Explanation
	1.	Root Logger and Appenders:
	â€¢	The log4j.rootLogger sets the base logging level (INFO) and assigns two appenders: one for rolling file output and one for console output.
	2.	Rolling File Appender:
	â€¢	The ROLLINGFILE appender writes logs to the file specified by the combination of ${zookeeper.log.dir} and ${zookeeper.log.file}.
	â€¢	The settings such as MaxFileSize and MaxBackupIndex control how the logs are rotated.
	3.	Console Appender:
	â€¢	The CONSOLE appender outputs logs to the standard output, which is helpful during development or troubleshooting.
	4.	Log Directory and File Configuration:
	â€¢	By setting zookeeper.log.dir to /var/log/zookeeper and zookeeper.log.file to zookeeper.log, you ensure that all ZooKeeper logs end up in /var/log/zookeeper/zookeeper.log.
	5.	Logger Levels for ZooKeeper Components:
	â€¢	Log levels are explicitly set for the main ZooKeeper classes (org.apache.zookeeper and org.apache.zookeeper.server) to ensure logs are captured as expected.

â¸»

References
	â€¢	îˆƒApache ZooKeeper GitHub Repository â€“ Logging Configurationîˆ„ â€“ Provides context on default logging practices and configurations for ZooKeeper.
	â€¢	îˆƒApache ZooKeeper Documentationîˆ„ â€“ Details on configuring and managing ZooKeeper, including logging setup.

This file can be placed in the ZooKeeper configuration directory (typically found at /etc/zookeeper/conf/ on RHEL/CentOS systems) to ensure logs are directed to the specified directory.


=======


Hereâ€™s a step-by-step installation guide for Apache Kafka 3.6.0 and Zookeeper 3.8.4 on 3 separate machines each, assuming youâ€™re using RHEL/CentOS-based systems and your repos (Kafka & Zookeeper) are available locally via Satellite.

â¸»

ğŸ”§ Prerequisites (on all machines)
	â€¢	Java 8 or 11 installed.
	â€¢	DNS resolution between all nodes or update /etc/hosts.
	â€¢	Static IPs.
	â€¢	Firewall rules opened for Zookeeper (2181) and Kafka (9092).
	â€¢	Unique hostnames for each node.

â¸»

ğŸ§­ Machines Map (Example)

Role	Hostname	IP Address
ZooKeeper1	zk1.example.com	192.168.1.101
ZooKeeper2	zk2.example.com	192.168.1.102
ZooKeeper3	zk3.example.com	192.168.1.103
Kafka1	kafka1.example.com	192.168.1.201
Kafka2	kafka2.example.com	192.168.1.202
Kafka3	kafka3.example.com	192.168.1.203



â¸»

ğŸ˜ Step 1: Install Zookeeper (3.8.4) on zk1, zk2, zk3

ğŸ”¹ Install Zookeeper

sudo yum install -y zookeeper zookeeper-server

ğŸ”¹ Configure Zookeeper

Edit /etc/zookeeper/zoo.cfg:

tickTime=2000
initLimit=10
syncLimit=5
dataDir=/var/lib/zookeeper
clientPort=2181
server.1=zk1.example.com:2888:3888
server.2=zk2.example.com:2888:3888
server.3=zk3.example.com:2888:3888

ğŸ”¹ Set myid

echo "1" > /var/lib/zookeeper/myid  # On zk1
echo "2" > /var/lib/zookeeper/myid  # On zk2
echo "3" > /var/lib/zookeeper/myid  # On zk3

ğŸ”¹ Start Zookeeper

sudo systemctl enable zookeeper
sudo systemctl start zookeeper



â¸»

ğŸ¦„ Step 2: Install Kafka (3.6.0) on kafka1, kafka2, kafka3

ğŸ”¹ Install Kafka

sudo yum install -y kafka kafka-server

ğŸ”¹ Configure Kafka (Example for kafka1)

Edit /etc/kafka/server.properties:

broker.id=1
log.dirs=/var/lib/kafka-logs
zookeeper.connect=zk1.example.com:2181,zk2.example.com:2181,zk3.example.com:2181
listeners=PLAINTEXT://kafka1.example.com:9092
advertised.listeners=PLAINTEXT://kafka1.example.com:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0

Update broker.id and advertised.listeners uniquely per Kafka node.

ğŸ”¹ Start Kafka

sudo systemctl enable kafka
sudo systemctl start kafka



â¸»

âœ… Step 3: Verify Setup

ğŸ”¹ Check Zookeeper

echo ruok | nc localhost 2181
# Should respond with: imok

ğŸ”¹ Check Kafka

kafka-topics.sh --bootstrap-server kafka1.example.com:9092 --list



â¸»

ğŸ” Step 4: Kafka Cluster Configuration (Optional)

After starting all nodes:
	1.	Create topics:

kafka-topics.sh --create --topic test --bootstrap-server kafka1.example.com:9092 --replication-factor 3 --partitions 3


	2.	Produce messages:

kafka-console-producer.sh --broker-list kafka1.example.com:9092 --topic test


	3.	Consume messages:

kafka-console-consumer.sh --bootstrap-server kafka1.example.com:9092 --topic test --from-beginning



â¸»

Would you like a systemd health check script or cluster monitoring setup next (Prometheus/Grafana or Kafka Manager)?


Great question!

ğŸ” TL;DR: The safest, most maintainable way to configure Kafka log directories without editing core Kafka scripts like kafka-server-start.sh is to use a custom systemd unit override that injects the required environment variables via /usr/bin/env.

â¸»

âœ… Recommended (Safe + Clean) Approach: systemd override with /usr/bin/env

Why itâ€™s better:
	â€¢	Doesnâ€™t modify Kafka binaries (survives upgrades).
	â€¢	No need to touch Kafkaâ€™s internal scripts.
	â€¢	Works reliably across RHEL/CentOS and Debian systems.
	â€¢	Easy to document and replicate in automation tools (like Ansible or Terraform).

ğŸ”§ Example override

sudo systemctl edit kafka

Paste:

[Service]
ExecStart=
ExecStart=/usr/bin/env \
  KAFKA_LOG4J_OPTS=-Dkafka.logs.dir=/var/log/kafka \
  KAFKA_HEAP_OPTS=-Xms2G -Xmx2G \
  KAFKA_JVM_PERFORMANCE_OPTS=-XX:+UseG1GC -Xlog:gc:/var/log/kafka/gc.log:time,uptime,level,tags:filecount=10,filesize=100M \
  /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties

Then:

sudo systemctl daemon-reexec
sudo systemctl daemon-reload
sudo systemctl restart kafka



â¸»

âš ï¸ Why editing kafka-server-start.sh is riskier:
	â€¢	Your changes may be overwritten by package upgrades.
	â€¢	Harder to maintain across multiple servers.
	â€¢	Scripts might break if upstream changes are introduced in newer Kafka versions.
	â€¢	Difficult to manage in large/automated deployments.

â¸»

ğŸ“Œ Summary

Method	Safety	Upgrade-Friendly	Best for Production
Systemd override with env	âœ… High	âœ… Yes	âœ… Yes
Editing kafka-server-start.sh	âŒ Low	âŒ No	ğŸš« No
Using /etc/sysconfig/kafka	âš ï¸ Medium (only works with RPM-based services that source it)	âŒ Often ignored	âš ï¸ OK sometimes



â¸»

Let me know if you want to bake this setup into an install script or Ansible playbook â€” happy to help!

